{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>A-fib/A-flutter</th>\n",
       "      <th>CAD</th>\n",
       "      <th>Carotid stenosis</th>\n",
       "      <th>CKD</th>\n",
       "      <th>DM</th>\n",
       "      <th>DM/ CKD</th>\n",
       "      <th>...</th>\n",
       "      <th>Overweight</th>\n",
       "      <th>PE</th>\n",
       "      <th>Previous MI</th>\n",
       "      <th>Previous Stroke</th>\n",
       "      <th>Previous Stroke/ Previous TIA</th>\n",
       "      <th>Prosthetic Heart Valve</th>\n",
       "      <th>PVD</th>\n",
       "      <th>Sickle Cell Disorder</th>\n",
       "      <th>Sleep Apnea</th>\n",
       "      <th>Smoker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>HI</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104</td>\n",
       "      <td>HI</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104</td>\n",
       "      <td>CA</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>CA</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103</td>\n",
       "      <td>CA</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Race Sex  Stroke  A-fib/A-flutter  CAD  Carotid stenosis  CKD  DM  \\\n",
       "0  105   HI   F       0                0    0                 0    1   0   \n",
       "1  104   HI   F       0                0    0                 0    1   0   \n",
       "2  104   CA   F       0                0    0                 0    1   0   \n",
       "3  104   CA   F       0                0    0                 0    1   0   \n",
       "4  103   CA   F       0                0    0                 0    1   0   \n",
       "\n",
       "   DM/ CKD  ...  Overweight  PE  Previous MI  Previous Stroke  \\\n",
       "0        0  ...           0   0            0                0   \n",
       "1        0  ...           0   0            0                0   \n",
       "2        0  ...           0   0            0                0   \n",
       "3        0  ...           0   0            0                0   \n",
       "4        0  ...           0   0            0                0   \n",
       "\n",
       "   Previous Stroke/ Previous TIA  Prosthetic Heart Valve  PVD  \\\n",
       "0                              0                       0    0   \n",
       "1                              0                       0    0   \n",
       "2                              0                       0    0   \n",
       "3                              0                       0    0   \n",
       "4                              0                       0    0   \n",
       "\n",
       "   Sickle Cell Disorder  Sleep Apnea  Smoker  \n",
       "0                     0            0       0  \n",
       "1                     0            0       0  \n",
       "2                     0            0       0  \n",
       "3                     0            0       0  \n",
       "4                     0            1       0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file into a pandas DataFrame\n",
    "data = pd.read_csv('data_adan.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>A-fib/A-flutter</th>\n",
       "      <th>CAD</th>\n",
       "      <th>Carotid stenosis</th>\n",
       "      <th>CKD</th>\n",
       "      <th>DM</th>\n",
       "      <th>DM/ CKD</th>\n",
       "      <th>DM/ PVD</th>\n",
       "      <th>Drugs/Alcohol Abuse</th>\n",
       "      <th>...</th>\n",
       "      <th>Race_AS</th>\n",
       "      <th>Race_BL</th>\n",
       "      <th>Race_CA</th>\n",
       "      <th>Race_HI</th>\n",
       "      <th>Race_NH</th>\n",
       "      <th>Race_OT</th>\n",
       "      <th>Race_PI</th>\n",
       "      <th>Race_UNK</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Stroke  A-fib/A-flutter  CAD  Carotid stenosis  CKD  DM  DM/ CKD  \\\n",
       "0  105       0                0    0                 0    1   0        0   \n",
       "1  104       0                0    0                 0    1   0        0   \n",
       "2  104       0                0    0                 0    1   0        0   \n",
       "3  104       0                0    0                 0    1   0        0   \n",
       "4  103       0                0    0                 0    1   0        0   \n",
       "\n",
       "   DM/ PVD  Drugs/Alcohol Abuse  ...  Race_AS  Race_BL  Race_CA  Race_HI  \\\n",
       "0        0                    0  ...        0        0        0        1   \n",
       "1        0                    0  ...        0        0        0        1   \n",
       "2        0                    0  ...        0        0        1        0   \n",
       "3        0                    0  ...        0        0        1        0   \n",
       "4        0                    0  ...        0        0        1        0   \n",
       "\n",
       "   Race_NH  Race_OT  Race_PI  Race_UNK  Sex_F  Sex_M  \n",
       "0        0        0        0         0      1      0  \n",
       "1        0        0        0         0      1      0  \n",
       "2        0        0        0         0      1      0  \n",
       "3        0        0        0         0      1      0  \n",
       "4        0        0        0         0      1      0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert categorical data into dummy data \n",
    "data = pd.get_dummies(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24201 entries, 0 to 24200\n",
      "Data columns (total 43 columns):\n",
      " #   Column                         Non-Null Count  Dtype\n",
      "---  ------                         --------------  -----\n",
      " 0   Age                            24201 non-null  int64\n",
      " 1   Stroke                         24201 non-null  int64\n",
      " 2   A-fib/A-flutter                24201 non-null  int64\n",
      " 3   CAD                            24201 non-null  int64\n",
      " 4   Carotid stenosis               24201 non-null  int64\n",
      " 5   CKD                            24201 non-null  int64\n",
      " 6   DM                             24201 non-null  int64\n",
      " 7   DM/ CKD                        24201 non-null  int64\n",
      " 8   DM/ PVD                        24201 non-null  int64\n",
      " 9   Drugs/Alcohol Abuse            24201 non-null  int64\n",
      " 10  DVT                            24201 non-null  int64\n",
      " 11  Dyslipidemia                   24201 non-null  int64\n",
      " 12  Familial hypercholesterolemia  24201 non-null  int64\n",
      " 13  Family History of Stroke       24201 non-null  int64\n",
      " 14  HF                             24201 non-null  int64\n",
      " 15  HRT                            24201 non-null  int64\n",
      " 16  HTN                            24201 non-null  int64\n",
      " 17  HTN/ CKD                       24201 non-null  int64\n",
      " 18  HTN/ HF                        24201 non-null  int64\n",
      " 19  HTN/ HF/ CKD                   24201 non-null  int64\n",
      " 20  Migraine                       24201 non-null  int64\n",
      " 21  Obesity                        24201 non-null  int64\n",
      " 22  Overweight                     24201 non-null  int64\n",
      " 23  PE                             24201 non-null  int64\n",
      " 24  Previous MI                    24201 non-null  int64\n",
      " 25  Previous Stroke                24201 non-null  int64\n",
      " 26  Previous Stroke/ Previous TIA  24201 non-null  int64\n",
      " 27  Prosthetic Heart Valve         24201 non-null  int64\n",
      " 28  PVD                            24201 non-null  int64\n",
      " 29  Sickle Cell Disorder           24201 non-null  int64\n",
      " 30  Sleep Apnea                    24201 non-null  int64\n",
      " 31  Smoker                         24201 non-null  int64\n",
      " 32  Race_AI                        24201 non-null  uint8\n",
      " 33  Race_AS                        24201 non-null  uint8\n",
      " 34  Race_BL                        24201 non-null  uint8\n",
      " 35  Race_CA                        24201 non-null  uint8\n",
      " 36  Race_HI                        24201 non-null  uint8\n",
      " 37  Race_NH                        24201 non-null  uint8\n",
      " 38  Race_OT                        24201 non-null  uint8\n",
      " 39  Race_PI                        24201 non-null  uint8\n",
      " 40  Race_UNK                       24201 non-null  uint8\n",
      " 41  Sex_F                          24201 non-null  uint8\n",
      " 42  Sex_M                          24201 non-null  uint8\n",
      "dtypes: int64(32), uint8(11)\n",
      "memory usage: 6.2 MB\n"
     ]
    }
   ],
   "source": [
    "#all dataframe columns\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24201, 17) (24201, 1)\n"
     ]
    }
   ],
   "source": [
    "#define X and y\n",
    "\n",
    "X = data[['Age','Race_AI', 'Race_AS', 'Race_BL', 'Race_CA', 'Race_HI', 'Race_NH', 'Race_OT', 'Race_PI', 'Race_UNK', 'Sex_F', 'Sex_M', 'HTN', 'Dyslipidemia', 'Carotid stenosis', 'CKD', 'DM']]\n",
    "y = data[\"Stroke\"].values.reshape(-1, 1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Race_AI', 'Race_AS', 'Race_BL', 'Race_CA', 'Race_HI', 'Race_NH',\n",
       "       'Race_OT', 'Race_PI', 'Race_UNK', 'Sex_F', 'Sex_M', 'HTN',\n",
       "       'Dyslipidemia', 'Carotid stenosis', 'CKD', 'DM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display columns of X \n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScater model and fit it to the training data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training and testing data using the X_scaler and y_scaler models\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.67229076, -0.04519659, -0.30964841, ..., -0.08942782,\n",
       "        -0.52502728, -0.53176702],\n",
       "       [ 0.67229076, -0.04519659, -0.30964841, ..., -0.08942782,\n",
       "         1.90466295, -0.53176702],\n",
       "       [ 0.04432385, -0.04519659, -0.30964841, ..., -0.08942782,\n",
       "        -0.52502728, -0.53176702],\n",
       "       ...,\n",
       "       [ 1.35258825, -0.04519659, -0.30964841, ..., -0.08942782,\n",
       "        -0.52502728, -0.53176702],\n",
       "       [ 0.61996019, -0.04519659, -0.30964841, ..., -0.08942782,\n",
       "        -0.52502728, -0.53176702],\n",
       "       [-1.89190745, -0.04519659, -0.30964841, ..., -0.08942782,\n",
       "        -0.52502728, -0.53176702]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjyoo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\hjyoo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the data\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9734986225895317\n",
      "Testing Data Score: 0.9730623037514461\n"
     ]
    }
   ],
   "source": [
    "#validate the model using the test data\n",
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes are either 0 (No Stroke) or 1 (Stroke)\n",
      "The new point was classified as: [0]\n"
     ]
    }
   ],
   "source": [
    "# test logistic model to predict Stroke/No Stroke fo 55 yr old caucasian male with no conditions\n",
    "new_data = np.array([[55,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0]])\n",
    "predictions = classifier.predict(new_data)\n",
    "print(\"Classes are either 0 (No Stroke) or 1 (Stroke)\")\n",
    "print(f\"The new point was classified as: {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes are either 0 (No Stroke) or 1 (Stroke)\n",
      "The new point was classified as: [1]\n"
     ]
    }
   ],
   "source": [
    "# test logistic model to predict Stroke/No Stroke for 55 yr old caucasian male with all conditions\n",
    "new_data = np.array([[55,0,0,0,1,0,0,0,0,0,0,1,1,1,1,1,1]])\n",
    "predictions = classifier.predict(new_data)\n",
    "print(\"Classes are either 0 (No Stroke) or 1 (Stroke)\")\n",
    "print(f\"The new point was classified as: {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a LinearRegression model and fit it to the scaled training data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions using the X_test_scaled data\n",
    "# Plot y_test_scaled vs y_test_scaled\n",
    "# Scatter plot y_test_scaled vs predictions\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "model.fit(X_train_scaled, y_train_scaled)\n",
    "plt.scatter(model.predict(X_train_scaled), model.predict(X_train_scaled) - y_train_scaled, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test_scaled), model.predict(X_test_scaled) - y_test_scaled, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_scaled.min(), xmax=y_test_scaled.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.7798376094505953, R2: 0.21151845746869022\n"
     ]
    }
   ],
   "source": [
    "# Used X_test_scaled, y_test_scaled, and model.predict(X_test_scaled) to calculate MSE and R2\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = model.score(X_test_scaled, y_test_scaled)\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neaural network with 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a normal neural network with 2 inputs, 6 hidden nodes, and 2 outputs\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=6, activation='relu', input_dim=17))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 108       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 14        \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18150 samples\n",
      "Epoch 1/100\n",
      "18150/18150 - 1s - loss: 0.2793 - accuracy: 0.9123\n",
      "Epoch 2/100\n",
      "18150/18150 - 1s - loss: 0.1288 - accuracy: 0.9717\n",
      "Epoch 3/100\n",
      "18150/18150 - 1s - loss: 0.1212 - accuracy: 0.9734\n",
      "Epoch 4/100\n",
      "18150/18150 - 1s - loss: 0.1192 - accuracy: 0.9735\n",
      "Epoch 5/100\n",
      "18150/18150 - 1s - loss: 0.1182 - accuracy: 0.9735\n",
      "Epoch 6/100\n",
      "18150/18150 - 1s - loss: 0.1176 - accuracy: 0.9735\n",
      "Epoch 7/100\n",
      "18150/18150 - 1s - loss: 0.1172 - accuracy: 0.9735\n",
      "Epoch 8/100\n",
      "18150/18150 - 1s - loss: 0.1169 - accuracy: 0.9735\n",
      "Epoch 9/100\n",
      "18150/18150 - 1s - loss: 0.1167 - accuracy: 0.9735\n",
      "Epoch 10/100\n",
      "18150/18150 - 1s - loss: 0.1165 - accuracy: 0.9735\n",
      "Epoch 11/100\n",
      "18150/18150 - 1s - loss: 0.1162 - accuracy: 0.9735\n",
      "Epoch 12/100\n",
      "18150/18150 - 1s - loss: 0.1163 - accuracy: 0.9735\n",
      "Epoch 13/100\n",
      "18150/18150 - 1s - loss: 0.1160 - accuracy: 0.9735\n",
      "Epoch 14/100\n",
      "18150/18150 - 1s - loss: 0.1160 - accuracy: 0.9735\n",
      "Epoch 15/100\n",
      "18150/18150 - 1s - loss: 0.1159 - accuracy: 0.9735\n",
      "Epoch 16/100\n",
      "18150/18150 - 1s - loss: 0.1158 - accuracy: 0.9735\n",
      "Epoch 17/100\n",
      "18150/18150 - 1s - loss: 0.1157 - accuracy: 0.9735\n",
      "Epoch 18/100\n",
      "18150/18150 - 1s - loss: 0.1158 - accuracy: 0.9734\n",
      "Epoch 19/100\n",
      "18150/18150 - 1s - loss: 0.1155 - accuracy: 0.9735\n",
      "Epoch 20/100\n",
      "18150/18150 - 1s - loss: 0.1155 - accuracy: 0.9735\n",
      "Epoch 21/100\n",
      "18150/18150 - 1s - loss: 0.1156 - accuracy: 0.9735\n",
      "Epoch 22/100\n",
      "18150/18150 - 1s - loss: 0.1155 - accuracy: 0.9735\n",
      "Epoch 23/100\n",
      "18150/18150 - 1s - loss: 0.1154 - accuracy: 0.9735\n",
      "Epoch 24/100\n",
      "18150/18150 - 1s - loss: 0.1154 - accuracy: 0.9735\n",
      "Epoch 25/100\n",
      "18150/18150 - 0s - loss: 0.1154 - accuracy: 0.9735\n",
      "Epoch 26/100\n",
      "18150/18150 - 1s - loss: 0.1154 - accuracy: 0.9735\n",
      "Epoch 27/100\n",
      "18150/18150 - 1s - loss: 0.1152 - accuracy: 0.9735\n",
      "Epoch 28/100\n",
      "18150/18150 - 1s - loss: 0.1153 - accuracy: 0.9735\n",
      "Epoch 29/100\n",
      "18150/18150 - 1s - loss: 0.1152 - accuracy: 0.9735\n",
      "Epoch 30/100\n",
      "18150/18150 - 1s - loss: 0.1152 - accuracy: 0.9735\n",
      "Epoch 31/100\n",
      "18150/18150 - 1s - loss: 0.1151 - accuracy: 0.9735\n",
      "Epoch 32/100\n",
      "18150/18150 - 1s - loss: 0.1152 - accuracy: 0.9735\n",
      "Epoch 33/100\n",
      "18150/18150 - 1s - loss: 0.1152 - accuracy: 0.9735\n",
      "Epoch 34/100\n",
      "18150/18150 - 1s - loss: 0.1151 - accuracy: 0.9735\n",
      "Epoch 35/100\n",
      "18150/18150 - 1s - loss: 0.1150 - accuracy: 0.9735\n",
      "Epoch 36/100\n",
      "18150/18150 - 1s - loss: 0.1149 - accuracy: 0.9735\n",
      "Epoch 37/100\n",
      "18150/18150 - 1s - loss: 0.1150 - accuracy: 0.9735\n",
      "Epoch 38/100\n",
      "18150/18150 - 1s - loss: 0.1150 - accuracy: 0.9735\n",
      "Epoch 39/100\n",
      "18150/18150 - 1s - loss: 0.1150 - accuracy: 0.9735\n",
      "Epoch 40/100\n",
      "18150/18150 - 1s - loss: 0.1150 - accuracy: 0.9735\n",
      "Epoch 41/100\n",
      "18150/18150 - 1s - loss: 0.1150 - accuracy: 0.9735\n",
      "Epoch 42/100\n",
      "18150/18150 - 1s - loss: 0.1150 - accuracy: 0.9735\n",
      "Epoch 43/100\n",
      "18150/18150 - 1s - loss: 0.1148 - accuracy: 0.9735\n",
      "Epoch 44/100\n",
      "18150/18150 - 1s - loss: 0.1149 - accuracy: 0.9735\n",
      "Epoch 45/100\n",
      "18150/18150 - 1s - loss: 0.1149 - accuracy: 0.9735\n",
      "Epoch 46/100\n",
      "18150/18150 - 1s - loss: 0.1148 - accuracy: 0.9735\n",
      "Epoch 47/100\n",
      "18150/18150 - 1s - loss: 0.1148 - accuracy: 0.9735\n",
      "Epoch 48/100\n",
      "18150/18150 - 1s - loss: 0.1148 - accuracy: 0.9735\n",
      "Epoch 49/100\n",
      "18150/18150 - 1s - loss: 0.1148 - accuracy: 0.9735\n",
      "Epoch 50/100\n",
      "18150/18150 - 1s - loss: 0.1149 - accuracy: 0.9735\n",
      "Epoch 51/100\n",
      "18150/18150 - 1s - loss: 0.1148 - accuracy: 0.9735\n",
      "Epoch 52/100\n",
      "18150/18150 - 1s - loss: 0.1148 - accuracy: 0.9735\n",
      "Epoch 53/100\n",
      "18150/18150 - 1s - loss: 0.1148 - accuracy: 0.9735\n",
      "Epoch 54/100\n",
      "18150/18150 - 1s - loss: 0.1148 - accuracy: 0.9735\n",
      "Epoch 55/100\n",
      "18150/18150 - 1s - loss: 0.1148 - accuracy: 0.9735\n",
      "Epoch 56/100\n",
      "18150/18150 - 1s - loss: 0.1147 - accuracy: 0.9735\n",
      "Epoch 57/100\n",
      "18150/18150 - 1s - loss: 0.1148 - accuracy: 0.9735\n",
      "Epoch 58/100\n",
      "18150/18150 - 1s - loss: 0.1146 - accuracy: 0.9735\n",
      "Epoch 59/100\n",
      "18150/18150 - 1s - loss: 0.1147 - accuracy: 0.9735\n",
      "Epoch 60/100\n",
      "18150/18150 - 1s - loss: 0.1147 - accuracy: 0.9735\n",
      "Epoch 61/100\n",
      "18150/18150 - 1s - loss: 0.1146 - accuracy: 0.9735\n",
      "Epoch 62/100\n",
      "18150/18150 - 1s - loss: 0.1147 - accuracy: 0.9735\n",
      "Epoch 63/100\n",
      "18150/18150 - 1s - loss: 0.1148 - accuracy: 0.9735\n",
      "Epoch 64/100\n",
      "18150/18150 - 1s - loss: 0.1146 - accuracy: 0.9735\n",
      "Epoch 65/100\n",
      "18150/18150 - 1s - loss: 0.1146 - accuracy: 0.9735\n",
      "Epoch 66/100\n",
      "18150/18150 - 1s - loss: 0.1146 - accuracy: 0.9735\n",
      "Epoch 67/100\n",
      "18150/18150 - 1s - loss: 0.1146 - accuracy: 0.9735\n",
      "Epoch 68/100\n",
      "18150/18150 - 1s - loss: 0.1147 - accuracy: 0.9735\n",
      "Epoch 69/100\n",
      "18150/18150 - 1s - loss: 0.1146 - accuracy: 0.9735\n",
      "Epoch 70/100\n",
      "18150/18150 - 1s - loss: 0.1146 - accuracy: 0.9735\n",
      "Epoch 71/100\n",
      "18150/18150 - 1s - loss: 0.1146 - accuracy: 0.9735\n",
      "Epoch 72/100\n",
      "18150/18150 - 1s - loss: 0.1146 - accuracy: 0.9735\n",
      "Epoch 73/100\n",
      "18150/18150 - 1s - loss: 0.1144 - accuracy: 0.9735\n",
      "Epoch 74/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 75/100\n",
      "18150/18150 - 1s - loss: 0.1146 - accuracy: 0.9735\n",
      "Epoch 76/100\n",
      "18150/18150 - 1s - loss: 0.1144 - accuracy: 0.9735\n",
      "Epoch 77/100\n",
      "18150/18150 - 1s - loss: 0.1146 - accuracy: 0.9735\n",
      "Epoch 78/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 79/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 80/100\n",
      "18150/18150 - 1s - loss: 0.1146 - accuracy: 0.9735\n",
      "Epoch 81/100\n",
      "18150/18150 - 1s - loss: 0.1143 - accuracy: 0.9735\n",
      "Epoch 82/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 83/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 84/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 85/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 86/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 87/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 88/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 89/100\n",
      "18150/18150 - 1s - loss: 0.1144 - accuracy: 0.9735\n",
      "Epoch 90/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 91/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 92/100\n",
      "18150/18150 - 1s - loss: 0.1144 - accuracy: 0.9735\n",
      "Epoch 93/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 94/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 95/100\n",
      "18150/18150 - 1s - loss: 0.1144 - accuracy: 0.9735\n",
      "Epoch 96/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 97/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 98/100\n",
      "18150/18150 - 1s - loss: 0.1144 - accuracy: 0.9735\n",
      "Epoch 99/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 100/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dbe53307c8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning Neaural network with 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=6, activation='relu', input_dim=17))\n",
    "deep_model.add(Dense(units=6, activation='relu'))\n",
    "deep_model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6)                 108       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 14        \n",
      "=================================================================\n",
      "Total params: 164\n",
      "Trainable params: 164\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18150 samples\n",
      "Epoch 1/100\n",
      "18150/18150 - 1s - loss: 0.2997 - accuracy: 0.8983\n",
      "Epoch 2/100\n",
      "18150/18150 - 1s - loss: 0.1321 - accuracy: 0.9656\n",
      "Epoch 3/100\n",
      "18150/18150 - 1s - loss: 0.1270 - accuracy: 0.9656\n",
      "Epoch 4/100\n",
      "18150/18150 - 1s - loss: 0.1254 - accuracy: 0.9656\n",
      "Epoch 5/100\n",
      "18150/18150 - 1s - loss: 0.1244 - accuracy: 0.9656\n",
      "Epoch 6/100\n",
      "18150/18150 - 1s - loss: 0.1236 - accuracy: 0.9656\n",
      "Epoch 7/100\n",
      "18150/18150 - 1s - loss: 0.1230 - accuracy: 0.9656\n",
      "Epoch 8/100\n",
      "18150/18150 - 1s - loss: 0.1222 - accuracy: 0.9657\n",
      "Epoch 9/100\n",
      "18150/18150 - 1s - loss: 0.1217 - accuracy: 0.9735\n",
      "Epoch 10/100\n",
      "18150/18150 - 1s - loss: 0.1209 - accuracy: 0.9735\n",
      "Epoch 11/100\n",
      "18150/18150 - 1s - loss: 0.1207 - accuracy: 0.9735\n",
      "Epoch 12/100\n",
      "18150/18150 - 1s - loss: 0.1201 - accuracy: 0.9735\n",
      "Epoch 13/100\n",
      "18150/18150 - 1s - loss: 0.1196 - accuracy: 0.9735\n",
      "Epoch 14/100\n",
      "18150/18150 - 1s - loss: 0.1192 - accuracy: 0.9735\n",
      "Epoch 15/100\n",
      "18150/18150 - 1s - loss: 0.1190 - accuracy: 0.9735\n",
      "Epoch 16/100\n",
      "18150/18150 - 1s - loss: 0.1186 - accuracy: 0.9735\n",
      "Epoch 17/100\n",
      "18150/18150 - 1s - loss: 0.1184 - accuracy: 0.9735\n",
      "Epoch 18/100\n",
      "18150/18150 - 1s - loss: 0.1181 - accuracy: 0.9735\n",
      "Epoch 19/100\n",
      "18150/18150 - 1s - loss: 0.1179 - accuracy: 0.9735\n",
      "Epoch 20/100\n",
      "18150/18150 - 1s - loss: 0.1177 - accuracy: 0.9735\n",
      "Epoch 21/100\n",
      "18150/18150 - 1s - loss: 0.1176 - accuracy: 0.9735\n",
      "Epoch 22/100\n",
      "18150/18150 - 1s - loss: 0.1173 - accuracy: 0.9735\n",
      "Epoch 23/100\n",
      "18150/18150 - 1s - loss: 0.1173 - accuracy: 0.9735\n",
      "Epoch 24/100\n",
      "18150/18150 - 1s - loss: 0.1170 - accuracy: 0.9735\n",
      "Epoch 25/100\n",
      "18150/18150 - 1s - loss: 0.1170 - accuracy: 0.9735\n",
      "Epoch 26/100\n",
      "18150/18150 - 1s - loss: 0.1170 - accuracy: 0.9735\n",
      "Epoch 27/100\n",
      "18150/18150 - 1s - loss: 0.1168 - accuracy: 0.9735\n",
      "Epoch 28/100\n",
      "18150/18150 - 1s - loss: 0.1166 - accuracy: 0.9735\n",
      "Epoch 29/100\n",
      "18150/18150 - 1s - loss: 0.1167 - accuracy: 0.9735\n",
      "Epoch 30/100\n",
      "18150/18150 - 1s - loss: 0.1164 - accuracy: 0.9735\n",
      "Epoch 31/100\n",
      "18150/18150 - 1s - loss: 0.1164 - accuracy: 0.9735\n",
      "Epoch 32/100\n",
      "18150/18150 - 1s - loss: 0.1163 - accuracy: 0.9735\n",
      "Epoch 33/100\n",
      "18150/18150 - 1s - loss: 0.1160 - accuracy: 0.9735\n",
      "Epoch 34/100\n",
      "18150/18150 - 1s - loss: 0.1159 - accuracy: 0.9735\n",
      "Epoch 35/100\n",
      "18150/18150 - 1s - loss: 0.1159 - accuracy: 0.9735\n",
      "Epoch 36/100\n",
      "18150/18150 - 1s - loss: 0.1160 - accuracy: 0.9735\n",
      "Epoch 37/100\n",
      "18150/18150 - 1s - loss: 0.1157 - accuracy: 0.9735\n",
      "Epoch 38/100\n",
      "18150/18150 - 1s - loss: 0.1155 - accuracy: 0.9735\n",
      "Epoch 39/100\n",
      "18150/18150 - 1s - loss: 0.1157 - accuracy: 0.9735\n",
      "Epoch 40/100\n",
      "18150/18150 - 1s - loss: 0.1157 - accuracy: 0.9735\n",
      "Epoch 41/100\n",
      "18150/18150 - 1s - loss: 0.1155 - accuracy: 0.9735\n",
      "Epoch 42/100\n",
      "18150/18150 - 1s - loss: 0.1155 - accuracy: 0.9735\n",
      "Epoch 43/100\n",
      "18150/18150 - 1s - loss: 0.1153 - accuracy: 0.9735\n",
      "Epoch 44/100\n",
      "18150/18150 - 1s - loss: 0.1153 - accuracy: 0.9735\n",
      "Epoch 45/100\n",
      "18150/18150 - 1s - loss: 0.1153 - accuracy: 0.9735\n",
      "Epoch 46/100\n",
      "18150/18150 - 1s - loss: 0.1152 - accuracy: 0.9735\n",
      "Epoch 47/100\n",
      "18150/18150 - 1s - loss: 0.1151 - accuracy: 0.9735\n",
      "Epoch 48/100\n",
      "18150/18150 - 1s - loss: 0.1149 - accuracy: 0.9735\n",
      "Epoch 49/100\n",
      "18150/18150 - 1s - loss: 0.1151 - accuracy: 0.9735\n",
      "Epoch 50/100\n",
      "18150/18150 - 1s - loss: 0.1150 - accuracy: 0.9735\n",
      "Epoch 51/100\n",
      "18150/18150 - 1s - loss: 0.1151 - accuracy: 0.9735\n",
      "Epoch 52/100\n",
      "18150/18150 - 1s - loss: 0.1148 - accuracy: 0.9735\n",
      "Epoch 53/100\n",
      "18150/18150 - 1s - loss: 0.1149 - accuracy: 0.9735\n",
      "Epoch 54/100\n",
      "18150/18150 - 1s - loss: 0.1149 - accuracy: 0.9735\n",
      "Epoch 55/100\n",
      "18150/18150 - 1s - loss: 0.1148 - accuracy: 0.9735\n",
      "Epoch 56/100\n",
      "18150/18150 - 1s - loss: 0.1148 - accuracy: 0.9735\n",
      "Epoch 57/100\n",
      "18150/18150 - 1s - loss: 0.1147 - accuracy: 0.9735\n",
      "Epoch 58/100\n",
      "18150/18150 - 1s - loss: 0.1143 - accuracy: 0.9735\n",
      "Epoch 59/100\n",
      "18150/18150 - 1s - loss: 0.1148 - accuracy: 0.9735\n",
      "Epoch 60/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 61/100\n",
      "18150/18150 - 1s - loss: 0.1146 - accuracy: 0.9735\n",
      "Epoch 62/100\n",
      "18150/18150 - 1s - loss: 0.1146 - accuracy: 0.9735\n",
      "Epoch 63/100\n",
      "18150/18150 - 1s - loss: 0.1143 - accuracy: 0.9735\n",
      "Epoch 64/100\n",
      "18150/18150 - 1s - loss: 0.1146 - accuracy: 0.9735\n",
      "Epoch 65/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 66/100\n",
      "18150/18150 - 1s - loss: 0.1143 - accuracy: 0.9735\n",
      "Epoch 67/100\n",
      "18150/18150 - 1s - loss: 0.1144 - accuracy: 0.9735\n",
      "Epoch 68/100\n",
      "18150/18150 - 1s - loss: 0.1143 - accuracy: 0.9735\n",
      "Epoch 69/100\n",
      "18150/18150 - 1s - loss: 0.1146 - accuracy: 0.9735\n",
      "Epoch 70/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 71/100\n",
      "18150/18150 - 1s - loss: 0.1144 - accuracy: 0.9735\n",
      "Epoch 72/100\n",
      "18150/18150 - 1s - loss: 0.1142 - accuracy: 0.9735\n",
      "Epoch 73/100\n",
      "18150/18150 - 1s - loss: 0.1145 - accuracy: 0.9735\n",
      "Epoch 74/100\n",
      "18150/18150 - 1s - loss: 0.1144 - accuracy: 0.9735\n",
      "Epoch 75/100\n",
      "18150/18150 - 1s - loss: 0.1143 - accuracy: 0.9735\n",
      "Epoch 76/100\n",
      "18150/18150 - 1s - loss: 0.1144 - accuracy: 0.9735\n",
      "Epoch 77/100\n",
      "18150/18150 - 1s - loss: 0.1144 - accuracy: 0.9735\n",
      "Epoch 78/100\n",
      "18150/18150 - 1s - loss: 0.1143 - accuracy: 0.9735\n",
      "Epoch 79/100\n",
      "18150/18150 - 1s - loss: 0.1142 - accuracy: 0.9735\n",
      "Epoch 80/100\n",
      "18150/18150 - 1s - loss: 0.1144 - accuracy: 0.9735\n",
      "Epoch 81/100\n",
      "18150/18150 - 1s - loss: 0.1141 - accuracy: 0.9735\n",
      "Epoch 82/100\n",
      "18150/18150 - 1s - loss: 0.1142 - accuracy: 0.9735\n",
      "Epoch 83/100\n",
      "18150/18150 - 1s - loss: 0.1142 - accuracy: 0.9735\n",
      "Epoch 84/100\n",
      "18150/18150 - 1s - loss: 0.1142 - accuracy: 0.9735\n",
      "Epoch 85/100\n",
      "18150/18150 - 1s - loss: 0.1140 - accuracy: 0.9735\n",
      "Epoch 86/100\n",
      "18150/18150 - 1s - loss: 0.1142 - accuracy: 0.9735\n",
      "Epoch 87/100\n",
      "18150/18150 - 1s - loss: 0.1141 - accuracy: 0.9735\n",
      "Epoch 88/100\n",
      "18150/18150 - 1s - loss: 0.1139 - accuracy: 0.9735\n",
      "Epoch 89/100\n",
      "18150/18150 - 1s - loss: 0.1142 - accuracy: 0.9735\n",
      "Epoch 90/100\n",
      "18150/18150 - 1s - loss: 0.1140 - accuracy: 0.9735\n",
      "Epoch 91/100\n",
      "18150/18150 - 1s - loss: 0.1143 - accuracy: 0.9735\n",
      "Epoch 92/100\n",
      "18150/18150 - 1s - loss: 0.1141 - accuracy: 0.9735\n",
      "Epoch 93/100\n",
      "18150/18150 - 1s - loss: 0.1140 - accuracy: 0.9735\n",
      "Epoch 94/100\n",
      "18150/18150 - 1s - loss: 0.1139 - accuracy: 0.9735\n",
      "Epoch 95/100\n",
      "18150/18150 - 1s - loss: 0.1139 - accuracy: 0.9735\n",
      "Epoch 96/100\n",
      "18150/18150 - 1s - loss: 0.1138 - accuracy: 0.9735\n",
      "Epoch 97/100\n",
      "18150/18150 - 1s - loss: 0.1139 - accuracy: 0.9735\n",
      "Epoch 98/100\n",
      "18150/18150 - 1s - loss: 0.1140 - accuracy: 0.9735\n",
      "Epoch 99/100\n",
      "18150/18150 - 1s - loss: 0.1139 - accuracy: 0.9735\n",
      "Epoch 100/100\n",
      "18150/18150 - 1s - loss: 0.1137 - accuracy: 0.9735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dbe66deb48>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6051/6051 - 0s - loss: 0.1177 - accuracy: 0.9731\n",
      "Normal Neural Network - Loss: 0.1177242390843457, Accuracy: 0.97306227684021\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6051/6051 - 0s - loss: 0.1212 - accuracy: 0.9729\n",
      "Deep Neural Network - Loss: 0.12115455583511177, Accuracy: 0.9728970527648926\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = deep_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
